import json
import re
from llama_cpp import Llama
from config import Config

class LocalAIClient:
    def __init__(self):
        self.config = Config()
        self.model = None
        self.load_model()
    
    def load_model(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω—É—é GGUF –º–æ–¥–µ–ª—å"""
        print("üîÑ –ó–∞–≥—Ä—É–∂–∞—é –ª–æ–∫–∞–ª—å–Ω—É—é AI –º–æ–¥–µ–ª—å...")
        
        try:
            self.model = Llama(
                model_path=self.config.LOCAL_MODEL_PATH,
                n_ctx=4096,  # –†–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                n_threads=6,  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤
                n_gpu_layers=0,  # 0 = —Ç–æ–ª—å–∫–æ CPU, –±–æ–ª—å—à–µ 0 = –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU
                verbose=False
            )
            print("‚úÖ –õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            raise
    
    def generate_response(self, prompt, system_message=None, max_tokens=None):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç —Å –ø–æ–º–æ—â—å—é –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        
        if not self.model:
            raise Exception("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è
        messages = []
        if system_message:
            messages.append({"role": "system", "content": system_message})
        messages.append({"role": "user", "content": prompt})
        
        try:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è llama-cpp
            prompt_text = self._format_messages(messages)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
            response = self.model(
                prompt=prompt_text,
                max_tokens=max_tokens or self.config.LOCAL_MODEL_MAX_TOKENS,
                temperature=self.config.LOCAL_MODEL_TEMPERATURE,
                stop=["</s>", "```", "###", "---"],
                echo=False,
                stream=False
            )
            
            text_response = response['choices'][0]['text'].strip()
            
            # –û—á–∏—â–∞–µ–º –æ—Ç–≤–µ—Ç
            cleaned_response = self._clean_response(text_response)
            
            return cleaned_response
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
            return f'{{"error": "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}"}}'
    
    def _format_messages(self, messages):
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        formatted_text = ""
        
        for message in messages:
            if message["role"] == "system":
                formatted_text += f"<s>[INST] <<SYS>>\n{message['content']}\n<</SYS>>\n\n"
            elif message["role"] == "user":
                if formatted_text.endswith("\n\n"):
                    formatted_text += f"{message['content']} [/INST]"
                else:
                    formatted_text += f"{message['content']} [/INST]"
            elif message["role"] == "assistant":
                formatted_text += f" {message['content']} </s>"
        
        return formatted_text
    
    def _clean_response(self, text):
        """–û—á–∏—â–∞–µ—Ç –æ—Ç–≤–µ—Ç –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç JSON –µ—Å–ª–∏ –µ—Å—Ç—å"""
        
        # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ JSON –≤ –æ—Ç–≤–µ—Ç–µ
        json_pattern = r'\{[\s\S]*\}'
        matches = re.findall(json_pattern, text)
        
        if matches:
            # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π JSON (–æ–±—ã—á–Ω–æ —ç—Ç–æ –æ—Å–Ω–æ–≤–Ω–æ–π –æ—Ç–≤–µ—Ç)
            return matches[-1]
        else:
            # –ï—Å–ª–∏ JSON –Ω–µ –Ω–∞–π–¥–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
            return text
    
    def chat_completion(self, messages, max_tokens=None):
        """–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Å OpenAI"""
        if not messages:
            return {"choices": [{"message": {"content": "No messages"}}]}
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º system message –∏ user message
        system_msg = ""
        user_msg = ""
        
        for msg in messages:
            if msg["role"] == "system":
                system_msg = msg["content"]
            elif msg["role"] == "user":
                user_msg = msg["content"]
        
        response_text = self.generate_response(
            prompt=user_msg,
            system_message=system_msg,
            max_tokens=max_tokens
        )
        
        return {
            "choices": [{
                "message": {
                    "content": response_text
                }
            }]
        }